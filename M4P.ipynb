{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc94c61a-5317-48ba-a65a-c2b4956c509a",
   "metadata": {},
   "source": [
    "# Convert MP3, MP4, M4a to text file\n",
    "\n",
    "### FILE FORMAT: this is a 4min 47 seconds recording file (m4a format)\n",
    "### FILE SIZE:   1164KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9387d4-ca95-41bb-a432-d4e7ab9efa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install SpeechRecognition\n",
    "# pip install pydub\n",
    "# !ffmpeg -version\n",
    "# pip install transformers torch\n",
    "# pip install python-docx\n",
    "# !pip install --upgrade pip setuptools wheel\n",
    "# !pip install cmake\n",
    "# !pip uninstall -y sentencepiece\n",
    "# !pip install sentencepiece\n",
    "# !pip install sentencepiece==0.1.96\n",
    "# !D:/Users/User/anaconda3/python.exe -m pip install --upgrade pip setuptools wheel\n",
    "# pip install sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de379c9a-241c-4fa3-b38e-a87910edb1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9c0bd4-9033-4de4-a3ed-e2d9664962b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "音频已转换为 WAV 格式\n"
     ]
    }
   ],
   "source": [
    "# Step 1: 将 M4A 文件转换为 WAV 格式\n",
    "audio = AudioSegment.from_file(\"D:/Recording.m4a\", format=\"m4a\")  # 请将路径调整为你的文件路径\n",
    "audio.export(\"D:/converted.wav\", format=\"wav\")\n",
    "print(\"音频已转换为 WAV 格式\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "097ca3b5-232b-49e0-8331-4f2d6e02d7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "语音识别结果： 啊好把这一部分的内容总结一下首先呢是一个人他有一个认知体系那么这个人认知体系他肯定会基于这个人的特色然后有一些特定的那个触发点那么这个出发点来自于这个人跟其他的事物进行一个交互那这个比如说他可能跟另一个人进行一段对话或者是看了一部电影看了一本书甚至死是听了一部而听了一个演讲然后他都会产生一些兴趣点或者是触发点但他觉得眼前一亮想要探索更多那么这些出发点之间的有一些可能是抢连结的有一些可能是弱连接的但是现在可能就在一段时间之后就就他就回忆不起来了但是强连接的呢他因为大脑比如说基于这个出发点他有很多在接受到这个出发点的时候他有很多联想比如说当然他是主动的进行联想或者是被动了一下然后呢这样的话就会让这个出发点呢就会牢牢的就是说被保留在了他的知识体系列在他的知识体系在这个范围内就不断的回扩大然后呢因为就是因为这个强连接那么这个新的知识听了这个出发点也变成了他只是体系的一个部分然后呢也在未来的使用当中更容易被调去但是但是那些弱点可能未来在未来的使用中就被遗忘就不会被调去了那么然后还有一个方法它能帮助我们去就是主动的去增强这些弱连结那么就是人为的进行主动的去教别人或者是去输出比如说路上一个视频写一段话当然在这个过程中呢他就会不断的主动的去掉去那么就会加深这个内容跟原有之体系的一些交互然后进行连接当然这部分如果要持续的话他就需要一个反馈那个反馈可能就是来自于比如说读者听众任何一个外部的环境那么这里就好像有一次的一些现象就是说我们在接收到好的反馈的时候我们的情感恼他会突然就会被激发他就会很快然后就是本人的一部分那么这个人做这个事情就非常有个动力我们想想一下你还来原来在在学校里面嗯跟就收到老师的表扬之类的或者是家长的这个认可那么就会特别有动力去把这个事情哦再见这里要干好但是呢如果遇到了负面的反馈的话那就要启动我们的理性脑那我们通过一种合理的解释不要掉入到这个方面富贵的这个循环里面这个负面的评价里面因为如果到了父母评价也那么人如果任由这个情绪控制的话那个情绪就会被外界影响就会也变得负面但其实这期的并不重要因为总会有一部分人他会因为我们的一些内容出出然后呢得到一些收益但是我们签订要讨论的是我们是不是这一部分内容它是经过我们精心打磨就是清新打造的就像书中描述的一样他说我想把我们的作品当成一个孩子一样带出去打扮的漂漂亮亮我觉得这个解释平衡的形象生动也让我觉得我对于做这个视频博主的这个事情有了一些深入的一些思考和理解我觉得这可以是一个很好的一个方向\n",
      "识别文本已保存到 D:/output.txt 文件中\n"
     ]
    }
   ],
   "source": [
    "# Step 2: 使用 Google 语音识别，将音频转为文本\n",
    "recognizer = sr.Recognizer()\n",
    "with sr.AudioFile(\"D:/converted.wav\") as source:\n",
    "    audio_data = recognizer.record(source)\n",
    "    text = recognizer.recognize_google(audio_data, language=\"zh-CN\")\n",
    "    print(\"语音识别结果：\", text)\n",
    "# 将识别的文本保存到 .txt 文件\n",
    "with open(\"D:/output.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(text)\n",
    "print(\"识别文本已保存到 D:/output.txt 文件中\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f22ff9-9daa-45d1-97e2-f2e5323c62cc",
   "metadata": {},
   "source": [
    "# Give the text to get a summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b3c5f-4c5d-4f99-9dab-69cd72487111",
   "metadata": {},
   "source": [
    "## 1.Hugging face library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93072649-1b9d-4577-b057-8e5cbb50f9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daef0cfe89384ff3a065584b21d0c40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\User\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--google--flan-t5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677bddf613f3484393120de1f1eef411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de29874598904a3092995c377c933714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11157ba7d0124057a1cc272d2320ad46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389a677642234a16b159a25476e3a82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c89850b08446b9a6b8effa202b9012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b364f8d5ccb34e6a956ba830b9507934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "优化后的文本已保存到 optimized_text.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# 加载Flan-T5 large模型和分词器\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# 读取外部文件中的文本\n",
    "with open(\"D:/output.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# 对输入文本进行tokenize并生成输出\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_length=100, num_beams=5, early_stopping=True)\n",
    "\n",
    "# 将生成的token解码为文本\n",
    "optimized_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# 将优化后的文本写入到新的输出文件\n",
    "with open(\"D:/optimized_text.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(optimized_text)\n",
    "\n",
    "print(\"优化后的文本已保存到 optimized_text.txt 文件中。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8bef92e-f3b9-471b-a0b3-a9256bc11af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0ba46df79c453f83aa74563dbe8406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/20.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\User\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--utrobinmv--t5_summary_en_ru_zh_base_2048. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3daa28ec3ed4236a988ff0dd1064ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.47M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c4f353b66b41cf8cc876fd03979fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c134098f1e834ac29946fb5238d07520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79f6fb001014ec5a52fd861caaced9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/809 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835c79c3f6224ac99c4addef03ec25fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.19G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d890a6a53a4dddbe96029ab05fa955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割后的句子: ['', '啊好把这一部分的内容总结一下', '首先呢是一个人他有一个认知体系', '那么这个人认知体系他肯定会基于这个人的特色', '然后有一些特定的那个触发点', '那么这个出发点来自于这个人跟其他的事物进行一个交互那这个比如说他可能跟另一个人进行一段对话或者是看了一部电影看了一本书甚至死是听了一部而听了一个演讲', '然后他都会产生一些兴趣点或者是触发点但他觉得眼前一亮想要探索更多', '那么这些出发点之间的有一些可能是抢连结的有一些可能是弱连接的但是现在可能就在一段时间', '之后就就他就回忆不起来了但是强连接的呢他因为大脑比如说基于这个出发点他有很多在接受到这个出发点的时候他有很多联想比如说当然他是主动的进行联想或者是被动了一下', '然后呢这样的话就会让这个出发点呢就会牢牢的就是说被保留在了他的知识体系列在他的知识体系在这个范围内就不断的回扩大', '然后呢因为就是因为这个强连接', '那么这个新的知识听了这个出发点也变成了他只是体系的一个部分', '然后呢也在未来的使用当中更容易被调去但是但是那些弱点可能未来在未来的使用中就被遗忘就不会被调去了', '那么', '然后还有一个方法它能帮助我们去就是主动的去增强这些弱连结', '那么就是人为的进行主动的去教别人或者是去输出比如说路上一个视频写一段话当然在这个过程中呢他就会不断的主动的去掉去', '那么就会加深这个内容跟原有之体系的一些交互', '然后进行连接当然这部分如果要持续的话他就需要一个反馈那个反馈可能就是来自于比如说读者听众任何一个外部的环境', '那么这里就好像有一次的一些现象就是说我们在接收到好的反馈的时候我们的情感恼他会突然就会被激发他就会很快', '然后就是本人的一部分', '那么这个人做这个事情就非常有个动力我们想想一下你还来原来在在学校里面', '嗯跟就收到老师的表扬之类的或者是家长的这个认可', '那么就会特别有动力去把这个事情哦再见这里要干好但是呢如果遇到了负面的反馈的话那就要启动我们的理性脑那我们通过一种合理的解释不要掉入到这个方面富贵的这个循环里面这个负面的评价里面因为如果到了父母评价也', '那么人如果任由这个情绪控制的话那个情绪就会被外界影响就会也变得负面但其实这期的并不重要因为总会有一部分人他会因为我们的一些内容出出', '然后呢得到一些收益但是我们签订要讨论的是我们是不是这一部分内容它是经过我们精心打磨就是清新打造的就像书中描述的一样他说', '我想把我们的作品当成一个孩子一样带出去打扮的漂漂亮亮', '我觉得这个解释平衡的形象生动也让', '我觉得我对于做这个视频博主的这个事情有了一些深入的一些思考和理解', '我觉得这可以是一个很好的一个方向']\n",
      "优化后的文本:\n",
      " 回顾一下这一部分的内容。 啊,把这一点总结一下。. 首先,是人他有一个认知体系。首先是他有意识体系,然后是一个人。. 这个人认知体系他肯定会基于这个人的特色。那么这个人认识体系他会基于他的特色:. 周二(10月14日)是英国人节。 有些有点儿了。. 那么这个出发点来自于这个人跟其他的事物进行一个交互,比如说他可能跟另一个人进行一段对话或者是看了一部电影看了一本书甚至死是听了一场演讲。. 2012年11月14日, 1979年9月30日早晨,他终于开始幻想。. 距离这些出发点之间的距离可能还有一段时间,但是现在可能已经一段时间了。. 后来就他就回忆不起来了但是强连接的呢?他因为大脑比如说基于这个出发点他有很多在接受到这个方向点的时候,他还有很多联想或者被动了一下。. 写在他的知识体系列在他的知识体系在这个范围内就不断的回扩大了。. 回想一下,这是不是有了这个强联吗?. 一个新的知识听了这个出发点,也变成了他只是体系的一部分。这个新知识听到了这一步。. 在未来的使用中更容易被调去,但那些弱点可能未来未来的如何使用中就被遗忘就不会被修正。. 那么,你是不是觉得你得了吗?. 一个方法可以帮助我们去的是主动的,改善弱连结。. 人为的进行主动的去教别人或者是去输出,比如说路上一个视频写一段话当然在这个过程中,他就就会不断的主动去掉去。. 这段文本将加深内容与原有的体系的一些交互。同时,文章也提到了将这一内容添加到了原创的版本。. 进行连接时,如果要持续,他就需要一个反馈这个反馈的人。. 我们在接收到好的反馈时,我们的情感刺激会突然被激发他就会很快。. 1994年11月14日,在荷兰首都吉隆坡,举行了一场音乐会。. 这个人做这个事情就非常有个动力,我们想想你还去原来在学校里面。. 嗯跟就收到老师的表扬之类的或者是家长的认可。学校的老师们对此表示欢迎。. 如果遇到了负面的反馈的话,就要启动我们的理性脑那我们通过一种合理的解释不要掉入到这个方面富贵的循环里面这个负面评价里面。. 那么人如果任由这个情绪控制的话,那个情绪就会被外界影响就会也变得负面,但其实这期的并不重要因为总会有一部分人他会因为我们的一些内容出出。. 我们签要讨论的我们是不是这一部分内容是经过我们精心打磨的清新打造的如同书中描述的。. 我想把我们的作品当成一个孩子一样带出去打扮的样子。. 我觉得这个解释平衡的形象生动也让这一点产生影响。. 想想做这个视频博主的感受。我对制作此视频感到担忧。. 我觉得这可以是一个很好的一个方向。在这一点上,我肯定会对这一点感到满意。.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# # 加载Flan-T5 large模型和分词器\n",
    "# model_name = \"uer/t5-v1_1-base-chinese-cluecorpussmall\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "model_name = \"utrobinmv/t5_summary_en_ru_zh_base_2048\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# 从文件读取无标点的输入文本\n",
    "with open(\"D:/output - Copy.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# 自动分割文本成更短的句子\n",
    "# 假设用“那么”、“然后”等词作为自然的分隔点插入句号\n",
    "split_text = re.sub(r\"(那么|然后|首先|所以|因此|之后|啊|嗯|我觉得|我想|我认为)\", r\". \\1\", input_text)\n",
    "split_sentences = split_text.split(\". \")  # 分割成短句子\n",
    "print(\"分割后的句子:\", split_sentences)\n",
    "\n",
    "# 对每个短句子生成优化后的文本\n",
    "optimized_sentences = []\n",
    "for sentence in split_sentences:\n",
    "    if sentence.strip():  # 忽略空白句子\n",
    "        # 移除 token_type_ids\n",
    "        inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "        inputs.pop(\"token_type_ids\", None)\n",
    "        \n",
    "        # 调用生成函数\n",
    "        outputs = model.generate(**inputs, max_length=300, num_beams=6, early_stopping=True)\n",
    "        optimized_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        optimized_sentences.append(optimized_sentence)\n",
    "\n",
    "# 将优化后的文本写入到输出文件\n",
    "with open(\"optimized_text.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\". \".join(optimized_sentences) + \".\")\n",
    "\n",
    "# 打印优化后的文本\n",
    "optimized_text = \". \".join(optimized_sentences) + \".\"\n",
    "print(\"优化后的文本:\\n\", optimized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e711d-eaa2-4541-8d76-6f0507f35000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a244549-e79c-4af6-b5bd-d0072cedaaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed878e1ccf084509a06bebc78940efb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\User\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--csebuetnlp--mT5_m2o_chinese_simplified_crossSum. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce96a85cc6084b479a9698f8b04e9026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c512195cfcd42a9b9cde597eae51e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08667a1d6f54ed3b14a4c572e2afa76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2b8f93715a4083a03baeb30b1cf174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割后的句子: ['', '啊好把这一部分的内容总结一下', '首先呢是一个人他有一个认知体系', '那么这个人认知体系他肯定会基于这个人的特色', '然后有一些特定的那个触发点', '那么这个出发点来自于这个人跟其他的事物进行一个交互那这个比如说他可能跟另一个人进行一段对话或者是看了一部电影看了一本书甚至死是听了一部而听了一个演讲', '然后他都会产生一些兴趣点或者是触发点但他觉得眼前一亮想要探索更多', '那么这些出发点之间的有一些可能是抢连结的有一些可能是弱连接的但是现在可能就在一段时间', '之后就就他就回忆不起来了但是强连接的呢他因为大脑比如说基于这个出发点他有很多在接受到这个出发点的时候他有很多联想比如说当然他是主动的进行联想或者是被动了一下', '然后呢这样的话就会让这个出发点呢就会牢牢的就是说被保留在了他的知识体系列在他的知识体系在这个范围内就不断的回扩大', '然后呢因为就是因为这个强连接', '那么这个新的知识听了这个出发点也变成了他只是体系的一个部分', '然后呢也在未来的使用当中更容易被调去但是但是那些弱点可能未来在未来的使用中就被遗忘就不会被调去了', '那么', '然后还有一个方法它能帮助我们去就是主动的去增强这些弱连结', '那么就是人为的进行主动的去教别人或者是去输出比如说路上一个视频写一段话当然在这个过程中呢他就会不断的主动的去掉去', '那么就会加深这个内容跟原有之体系的一些交互', '然后进行连接当然这部分如果要持续的话他就需要一个反馈那个反馈可能就是来自于比如说读者听众任何一个外部的环境', '那么这里就好像有一次的一些现象就是说我们在接收到好的反馈的时候我们的情感恼他会突然就会被激发他就会很快', '然后就是本人的一部分', '那么这个人做这个事情就非常有个动力我们想想一下你还来原来在在学校里面', '嗯跟就收到老师的表扬之类的或者是家长的这个认可', '那么就会特别有动力去把这个事情哦再见这里要干好但是呢如果遇到了负面的反馈的话那就要启动我们的理性脑那我们通过一种合理的解释不要掉入到这个方面富贵的这个循环里面这个负面的评价里面因为如果到了父母评价也', '那么人如果任由这个情绪控制的话那个情绪就会被外界影响就会也变得负面但其实这期的并不重要因为总会有一部分人他会因为我们的一些内容出出', '然后呢得到一些收益但是我们签订要讨论的是我们是不是这一部分内容它是经过我们精心打磨就是清新打造的就像书中描述的一样他说', '我想把我们的作品当成一个孩子一样带出去打扮的漂漂亮亮', '我觉得这个解释平衡的形象生动也让', '我觉得我对于做这个视频博主的这个事情有了一些深入的一些思考和理解', '我觉得这可以是一个很好的一个方向']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047e7080e28d4884a9798275d377ec4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "优化后的文本:\n",
      " <extra_id_59> 香港大学校长黄之锋最近写了一篇 的 特写。. <extra_id_59> 在中美贸易战的紧张局势中,还存在另一个争议—合成的人。. <extra_id_59> 人类的认知这种看法究竟是什么?. <extra_id_59> 新冠病毒在全球肆虐至今,已经造成超过四千万人感染、超过一百万人死亡。. <extra_id_59> 你有没有遇到过类似情况:向朋友抱怨和伴侣之间的问题,但他们却觉得没什么好担心的?又或者你觉得朋友的新对象完全不适合,但他俩感情却越来越好?. <extra_id_59> 在爱丁堡大学校园里,坐落着一位名叫丹(Dan)的艺术家。. <extra_id_59> 在过去的25年里,全球两个超级大国之间出现了一道桥梁。. <extra_id_59> 首先来到了小时候的雷蒙德还是一个小孩了。原来的他因为在起初的记忆中出现了一个原来的强连接。. <extra_id_59> 以阅读一下耶路撒冷的创始人兼作家马克·J·塞弗尔(Mark J Seifer)的《知识分子》是怎么回事?. <extra_id_59> 在美国华盛顿的防空识别站上,人们发现了来自北美和东亚的防空识别系统。. <extra_id_59> 上世纪80年代初,科学界就的一个概念提出了一个新的概念。. <extra_id_59> 许多人为了在未来的电脑上能发现的一些尖端和不一致的switching功能而遭到破坏。. <extra_id_59> BBC 英伦网 报道称, 香港铜锣湾书店星期一(12月27日)新楼声称有人正在破坏他们的牙齿。. <extra_id_59> 新冠病毒疫情不是人类第一次面对重大危机。. <extra_id_59> 跟在网上打交道的时候,你是不是会遇到过寻求帮助?. <extra_id_59> 在中美贸易战的紧张局势中,还存在一些误解。. <extra_id_59> 视频共享应用程序提供联络是否存在漏洞?. <extra_id_59> 有一次,詹姆斯(Boo James)女士搭乘公共汽车,看到一名陌生女子向她招手。当时,她没有多想,事后才知道其实那是她的亲妈。. <extra_id_59> 2016年9月, 哈里王子和妻子梅根宣布,他们正在日本访问。. <extra_id_59> 新学期开学在即,有很多在英格兰和威尔士的学子第一次踏进大学校园。. <extra_id_59> 家常便饭的老师,对学校的反应不一。. <extra_id_59> 我相信你肯定同意我的这个看法:人们通常会认为你认为自己有多聪明。. <extra_id_59> 你是否压力过大,不堪重负,任务繁多?. <extra_id_59> 经过了大约两年的调查和研究,我们决定把《哈利·波特》杂志的一些视频分享给大家。. <extra_id_59> 2016年发生许多大事件,以下是各地通讯社摄影记者拍到最好看的照片。. <extra_id_59> 毛泽东的新年致辞被外界赞赏。. <extra_id_59> BBC中文网采访了一位视频博主,请他谈谈对这个视频分享网站的看法。. <extra_id_59> 新冠病毒给全球经济带来重创。.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"csebuetnlp/mT5_m2o_chinese_simplified_crossSum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# 从文件读取无标点的输入文本\n",
    "with open(\"D:/output - Copy.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# 自动分割文本成更短的句子\n",
    "# 假设用“那么”、“然后”等词作为自然的分隔点插入句号\n",
    "split_text = re.sub(r\"(那么|然后|首先|所以|因此|之后|啊|嗯|我觉得|我想|我认为)\", r\". \\1\", input_text)\n",
    "split_sentences = split_text.split(\". \")  # 分割成短句子\n",
    "print(\"分割后的句子:\", split_sentences)\n",
    "\n",
    "# 对每个短句子生成优化后的文本\n",
    "optimized_sentences = []\n",
    "for sentence in split_sentences:\n",
    "    if sentence.strip():  # 忽略空白句子\n",
    "        # 移除 token_type_ids\n",
    "        inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "        inputs.pop(\"token_type_ids\", None)\n",
    "        \n",
    "        # 调用生成函数\n",
    "        outputs = model.generate(**inputs, max_length=300, num_beams=6, early_stopping=True)\n",
    "        optimized_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        optimized_sentences.append(optimized_sentence)\n",
    "\n",
    "# 将优化后的文本写入到输出文件\n",
    "with open(\"optimized_text.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\". \".join(optimized_sentences) + \".\")\n",
    "\n",
    "# 打印优化后的文本\n",
    "optimized_text = \". \".join(optimized_sentences) + \".\"\n",
    "print(\"优化后的文本:\\n\", optimized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa695c7e-6a03-44c9-9c12-a532be55047b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割后的句子: ['', '啊好把这一部分的内容总结一下', '首先呢是一个人他有一个认知体系', '那么这个人认知体系他肯定会基于这个人的特色', '然后有一些特定的那个触发点', '那么这个出发点来自于这个人跟其他的事物进行一个交互那这个比如说他可能跟另一个人进行一段对话或者是看了一部电影看了一本书甚至死是听了一部而听了一个演讲', '然后他都会产生一些兴趣点或者是触发点但他觉得眼前一亮想要探索更多', '那么这些出发点之间的有一些可能是抢连结的有一些可能是弱连接的但是现在可能就在一段时间', '之后就就他就回忆不起来了但是强连接的呢他因为大脑比如说基于这个出发点他有很多在接受到这个出发点的时候他有很多联想比如说当然他是主动的进行联想或者是被动了一下', '然后呢这样的话就会让这个出发点呢就会牢牢的就是说被保留在了他的知识体系列在他的知识体系在这个范围内就不断的回扩大', '然后呢因为就是因为这个强连接', '那么这个新的知识听了这个出发点也变成了他只是体系的一个部分', '然后呢也在未来的使用当中更容易被调去但是但是那些弱点可能未来在未来的使用中就被遗忘就不会被调去了', '那么', '然后还有一个方法它能帮助我们去就是主动的去增强这些弱连结', '那么就是人为的进行主动的去教别人或者是去输出比如说路上一个视频写一段话当然在这个过程中呢他就会不断的主动的去掉去', '那么就会加深这个内容跟原有之体系的一些交互', '然后进行连接当然这部分如果要持续的话他就需要一个反馈那个反馈可能就是来自于比如说读者听众任何一个外部的环境', '那么这里就好像有一次的一些现象就是说我们在接收到好的反馈的时候我们的情感恼他会突然就会被激发他就会很快', '然后就是本人的一部分', '那么这个人做这个事情就非常有个动力我们想想一下你还来原来在在学校里面', '嗯跟就收到老师的表扬之类的或者是家长的这个认可', '那么就会特别有动力去把这个事情哦再见这里要干好但是呢如果遇到了负面的反馈的话那就要启动我们的理性脑那我们通过一种合理的解释不要掉入到这个方面富贵的这个循环里面这个负面的评价里面因为如果到了父母评价也', '那么人如果任由这个情绪控制的话那个情绪就会被外界影响就会也变得负面但其实这期的并不重要因为总会有一部分人他会因为我们的一些内容出出', '然后呢得到一些收益但是我们签订要讨论的是我们是不是这一部分内容它是经过我们精心打磨就是清新打造的就像书中描述的一样他说', '我想把我们的作品当成一个孩子一样带出去打扮的漂漂亮亮', '我觉得这个解释平衡的形象生动也让', '我觉得我对于做这个视频博主的这个事情有了一些深入的一些思考和理解', '我觉得这可以是一个很好的一个方向']\n",
      "生成的最终摘要:\n",
      " <extra_id_59> 香港大学校长黄之锋最近写了一篇 的 特写。 <extra_id_59> 在中美贸易战的紧张局势中,还存在另一个争议—合成的人。 <extra_id_59> 人类的认知这种看法究竟是什么? <extra_id_59> 新冠病毒在全球肆虐至今,已经造成超过四千万人感染、超过一百万人死亡。 <extra_id_59> 你有没有遇到过类似情况:向朋友抱怨和伴侣之间的问题,但他们却觉得没什么好担心的?又或者你觉得朋友的新对象完全不适合,但他俩感情却越来越好? <extra_id_59> 在爱丁堡一隅,坐落着一位名叫阿纳斯塔的神秘博士。 <extra_id_59> 在过去的25年里,全球两个超级大国之间出现了一道桥梁。 <extra_id_59> 首先来到了小时候的雷蒙德还是一个小孩了。原来的他因为在起初的记忆中出现了一个强连接的地方。 <extra_id_59> 以阅读一下耶路撒冷的创始人兼作家马克·J·塞弗尔(Mark J Seifer)的《哈利·波特》是一位很有意思的人。 <extra_id_59> 你可能听说过在加州和加拿大之间存在网络信号吗? <extra_id_59> 从2000年开始,英国就开始了有关知识的实验。 <extra_id_59> 许多人为了在未来的电脑上能发现的一些尖端和不一致的加密数字装置而遭到破坏。 <extra_id_59> BBC 英伦网 在此访问中分享了来自法国诺贝尔和平奖得主的经验。 <extra_id_59> 新冠病毒疫情不是人类第一次面对重大危机。 <extra_id_59> 你是不是因为在网上遇到过寻求帮助? <extra_id_59> 在中美贸易战的紧张局势中,还存在一些误解。 <extra_id_59> 监视一下你是否仍在使用某种方式? <extra_id_59> 有一次,詹姆斯(Boo James)女士搭乘公共汽车,看到一名陌生女子向她招手。当时,她没有多想,事后才知道其实那是她的亲妈。 <extra_id_59> 2016年9月, 哈里王子和妻子梅根相继辞职,离开香港,开始了一年之久的访问。 <extra_id_59> 在美国,很多留学生抱怨说希望自己的孩子丢到考场。 <extra_id_59> 家常便饭的老师,对学校的反应不一。 <extra_id_59> 我相信你肯定同意我的这个看法:人们通常会认为你觉得自己有多聪明,不是吗? <extra_id_59> 你是否压力过大,不堪重负,任务繁多? <extra_id_59> 经过了大约两年的调查和研究,我们决定把一本书的外形提交给《哈利·波特》。书中描述了这本书的一些经过改编而成的回忆录,希望能够帮助你获得高达15万英镑的收益。 <extra_id_59> 新冠病毒疫情让很多国家陷入凋零。 <extra_id_59> 毛泽东和陈水扁接受了特朗普总统的电话通话。 <extra_id_59> BBC中文网采访了一位访问过一个视频博主的经过。 <extra_id_59> 在美国访问的美国总统奥巴马,对布鲁克林的一个重要问题表示了支持。\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# 去除多余的空白和换行符\n",
    "WHITESPACE_HANDLER = lambda k: re.sub(r'\\s+', ' ', re.sub(r'\\n+', ' ', k.strip()))\n",
    "\n",
    "# 从文件读取无标点的输入文本\n",
    "with open(\"D:/output - Copy.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    article_text = file.read()\n",
    "    \n",
    "# 加载 mT5 模型和分词器\n",
    "model_name = \"csebuetnlp/mT5_m2o_chinese_simplified_crossSum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# 按关键词分割文本成较短的句子\n",
    "split_text = re.sub(r\"(那么|然后|首先|所以|因此|之后|啊|嗯|我觉得|我想|我认为)\", r\". \\1\", article_text)\n",
    "split_sentences = split_text.split(\". \")  # 分割成短句子\n",
    "print(\"分割后的句子:\", split_sentences)\n",
    "\n",
    "# 对每个短句生成摘要\n",
    "summary_chunks = []\n",
    "for sentence in split_sentences:\n",
    "    cleaned_sentence = WHITESPACE_HANDLER(sentence)\n",
    "    if cleaned_sentence:  # 忽略空白句子\n",
    "        input_ids = tokenizer(\n",
    "            [cleaned_sentence],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        )[\"input_ids\"]\n",
    "\n",
    "        # 生成摘要\n",
    "        output_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=150,  # 控制每段摘要的最大长度\n",
    "            no_repeat_ngram_size=2,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )[0]\n",
    "\n",
    "        # 解码生成的摘要\n",
    "        summary_chunk = tokenizer.decode(\n",
    "            output_ids,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        summary_chunks.append(summary_chunk)\n",
    "\n",
    "# 合并所有段落摘要为最终摘要\n",
    "final_summary = \" \".join(summary_chunks)\n",
    "print(\"生成的最终摘要:\\n\", final_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "025dac02-bd78-4651-bfb2-b62d88ffe792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.54.3-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.7.0-cp311-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: sniffio in d:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\users\\user\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in d:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: colorama in d:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.54.3-py3-none-any.whl (389 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.7.0-cp311-none-win_amd64.whl (205 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: jiter, h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.7.0 openai-1.54.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab9f6b-00a4-4b93-b47d-6506fc5a14e1",
   "metadata": {},
   "source": [
    "## 2. OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2b73457-a630-46dd-80f2-cb6bdd140eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test.\n"
     ]
    }
   ],
   "source": [
    "# test cases\n",
    "\n",
    "import openai\n",
    "\n",
    "# 设置 API 密钥\n",
    "openai.api_key = \"sk-\"\n",
    "\n",
    "# 调用 GPT-4 模型并生成对话\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o\",\n",
    "    # model=\"gpt-4-0613\",\n",
    "\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Say this is a test\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 打印生成的回复\n",
    "print(response['choices'][0]['message']['content'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c5367fe-bb5c-469a-be53-8caa1e68e6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割后的句子: ['', '啊好把这一部分的内容总结一下', '首先呢是一个人他有一个认知体系', '那么这个人认知体系他肯定会基于这个人的特色', '然后有一些特定的那个触发点', '那么这个出发点来自于这个人跟其他的事物进行一个交互那这个比如说他可能跟另一个人进行一段对话或者是看了一部电影看了一本书甚至死是听了一部而听了一个演讲', '然后他都会产生一些兴趣点或者是触发点但他觉得眼前一亮想要探索更多', '那么这些出发点之间的有一些可能是抢连结的有一些可能是弱连接的但是现在可能就在一段时间', '之后就就他就回忆不起来了但是强连接的呢他因为大脑比如说基于这个出发点他有很多在接受到这个出发点的时候他有很多联想比如说当然他是主动的进行联想或者是被动了一下', '然后呢这样的话就会让这个出发点呢就会牢牢的就是说被保留在了他的知识体系列在他的知识体系在这个范围内就不断的回扩大', '然后呢因为就是因为这个强连接', '那么这个新的知识听了这个出发点也变成了他只是体系的一个部分', '然后呢也在未来的使用当中更容易被调去但是但是那些弱点可能未来在未来的使用中就被遗忘就不会被调去了', '那么', '然后还有一个方法它能帮助我们去就是主动的去增强这些弱连结', '那么就是人为的进行主动的去教别人或者是去输出比如说路上一个视频写一段话当然在这个过程中呢他就会不断的主动的去掉去', '那么就会加深这个内容跟原有之体系的一些交互', '然后进行连接当然这部分如果要持续的话他就需要一个反馈那个反馈可能就是来自于比如说读者听众任何一个外部的环境', '那么这里就好像有一次的一些现象就是说我们在接收到好的反馈的时候我们的情感恼他会突然就会被激发他就会很快', '然后就是本人的一部分', '那么这个人做这个事情就非常有个动力我们想想一下你还来原来在在学校里面', '嗯跟就收到老师的表扬之类的或者是家长的这个认可', '那么就会特别有动力去把这个事情哦再见这里要干好但是呢如果遇到了负面的反馈的话那就要启动我们的理性脑那我们通过一种合理的解释不要掉入到这个方面富贵的这个循环里面这个负面的评价里面因为如果到了父母评价也', '那么人如果任由这个情绪控制的话那个情绪就会被外界影响就会也变得负面但其实这期的并不重要因为总会有一部分人他会因为我们的一些内容出出', '然后呢得到一些收益但是我们签订要讨论的是我们是不是这一部分内容它是经过我们精心打磨就是清新打造的就像书中描述的一样他说', '我想把我们的作品当成一个孩子一样带出去打扮的漂漂亮亮', '我觉得这个解释平衡的形象生动也让', '我觉得我对于做这个视频博主的这个事情有了一些深入的一些思考和理解', '我觉得这可以是一个很好的一个方向']\n",
      "生成的最终摘要:\n",
      " 内容概述：这部分内容主要讲述了一个人的认知体系。 这段内容讲述的是一个人通过与其他人或事物的交互（如对话、看电影、读书或听演讲）产生兴趣点或触发点，进而产生探索更多的欲望。这些触发点之间可能存在强连接或弱连接。 该内容主要讨论了新知识如何成为知识体系的一部分，并指出强连接的知识更易在未来使用中被调用，而弱连接的知识可能会被遗忘。 该内容主要讨论了主动教授和输出信息的重要性，如制作视频或写作，这样可以加深对内容的理解并与原有体系进行交互。为了持续进行，需要来自读者或听众等外部环境的反馈。 这段内容主要讲述了个人动力的来源和如何处理负面反馈。一方面，得到老师或家长的表扬和认可可以激发个人的积极性和动力；另一方面，遇到负面反馈时，需要启动理性思考，通过合理的解释避免陷入 该内容表达了作者将作品视如己出，希望精心打扮、展现其美好的愿望，并且通过做视频博主，对此事有了深入的思考和理解。\n"
     ]
    }
   ],
   "source": [
    "# summarize every 5 sentences.\n",
    "\n",
    "import re\n",
    "import openai\n",
    "\n",
    "# 设置 API 密钥\n",
    "openai.api_key = \"sk-\n",
    "\n",
    "\n",
    "# 从文件读取无标点的输入文本\n",
    "with open(\"D:/output - Copy.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    article_text = file.read()\n",
    "    \n",
    "# 按关键词分割文本成较短的句子\n",
    "split_text = re.sub(r\"(那么|然后|首先|所以|因此|之后|啊|嗯|我觉得|我想|我认为)\", r\". \\1\", article_text)\n",
    "split_sentences = split_text.split(\". \")  # 分割成短句子\n",
    "print(\"分割后的句子:\", split_sentences)\n",
    "\n",
    "# 每 3-4 句话合并为一个段落\n",
    "grouped_sentences = [\" \".join(split_sentences[i:i+3]) for i in range(0, len(split_sentences), 3)]\n",
    "\n",
    "# 对每个段落生成摘要\n",
    "summary_chunks = []\n",
    "for paragraph in grouped_sentences:\n",
    "    if paragraph.strip():  # 忽略空白段落\n",
    "        for attempt in range(3):  # 最多重试 3 次\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-4\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"你是一个帮助生成简短摘要的助手。\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"请对以下内容生成简短的中文摘要：{paragraph}\"}\n",
    "                    ],\n",
    "                    max_tokens=100,  # 设置 max_tokens 以限制摘要长度\n",
    "                    temperature=0.5\n",
    "                )\n",
    "                summary = response['choices'][0]['message']['content']\n",
    "                summary_chunks.append(summary)\n",
    "                break  # 成功后跳出重试循环\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                time.sleep(5)  # 等待几秒后重试\n",
    "\n",
    "# 合并所有句子的摘要\n",
    "final_summary = \" \".join(summary_chunks)\n",
    "print(\"生成的最终摘要:\\n\", final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "205ff583-c47b-4fb2-9e63-6b8f6b05840e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割后的句子: ['', '啊好把这一部分的内容总结一下', '首先呢是一个人他有一个认知体系', '那么这个人认知体系他肯定会基于这个人的特色', '然后有一些特定的那个触发点', '那么这个出发点来自于这个人跟其他的事物进行一个交互那这个比如说他可能跟另一个人进行一段对话或者是看了一部电影看了一本书甚至死是听了一部而听了一个演讲', '然后他都会产生一些兴趣点或者是触发点但他觉得眼前一亮想要探索更多', '那么这些出发点之间的有一些可能是抢连结的有一些可能是弱连接的但是现在可能就在一段时间', '之后就就他就回忆不起来了但是强连接的呢他因为大脑比如说基于这个出发点他有很多在接受到这个出发点的时候他有很多联想比如说当然他是主动的进行联想或者是被动了一下', '然后呢这样的话就会让这个出发点呢就会牢牢的就是说被保留在了他的知识体系列在他的知识体系在这个范围内就不断的回扩大', '然后呢因为就是因为这个强连接', '那么这个新的知识听了这个出发点也变成了他只是体系的一个部分', '然后呢也在未来的使用当中更容易被调去但是但是那些弱点可能未来在未来的使用中就被遗忘就不会被调去了', '那么', '然后还有一个方法它能帮助我们去就是主动的去增强这些弱连结', '那么就是人为的进行主动的去教别人或者是去输出比如说路上一个视频写一段话当然在这个过程中呢他就会不断的主动的去掉去', '那么就会加深这个内容跟原有之体系的一些交互', '然后进行连接当然这部分如果要持续的话他就需要一个反馈那个反馈可能就是来自于比如说读者听众任何一个外部的环境', '那么这里就好像有一次的一些现象就是说我们在接收到好的反馈的时候我们的情感恼他会突然就会被激发他就会很快', '然后就是本人的一部分', '那么这个人做这个事情就非常有个动力我们想想一下你还来原来在在学校里面', '嗯跟就收到老师的表扬之类的或者是家长的这个认可', '那么就会特别有动力去把这个事情哦再见这里要干好但是呢如果遇到了负面的反馈的话那就要启动我们的理性脑那我们通过一种合理的解释不要掉入到这个方面富贵的这个循环里面这个负面的评价里面因为如果到了父母评价也', '那么人如果任由这个情绪控制的话那个情绪就会被外界影响就会也变得负面但其实这期的并不重要因为总会有一部分人他会因为我们的一些内容出出', '然后呢得到一些收益但是我们签订要讨论的是我们是不是这一部分内容它是经过我们精心打磨就是清新打造的就像书中描述的一样他说', '我想把我们的作品当成一个孩子一样带出去打扮的漂漂亮亮', '我觉得这个解释平衡的形象生动也让', '我觉得我对于做这个视频博主的这个事情有了一些深入的一些思考和理解', '我觉得这可以是一个很好的一个方向']\n",
      "\n",
      "\n",
      "生成的最终摘要:\n",
      " 这部分内容主要介绍了一个人和他的认知体系。 该内容主要讨论了个体与外部事物交互过程中可能产生的触发点，这些触发点可能源于对话、观看电影、阅读书籍或听演讲等，这些都可能引发个体的兴趣，并激发他们探索更多知识的欲望。 该内容讲述了人的大脑如何通过强连接记忆和联想信息。当接触到某个出发点时，大脑会主动或被动地进行联想，这使得出发点能够牢固地保留在知识体系中，并在这个体系内不断扩大。强连接在这个 该内容主要讨论了在未来使用中，弱点可能会被忽视，但我们可以主动增强这些弱连结以改善这种情况。 内容与原有体系的交互深化，需要持续的反馈，这可能来自读者、听众或任何外部环境。当接收到好的反馈时，我们的情感会被激发。 这段话讲述了人在得到正面反馈（如老师表扬或家长认可）时会有更强的动力去完成事情，而在面对负面反馈时，应启动理性思考，通过合理解释避免陷入负面评价的循环。 我们正在讨论的是我们精心打造和打磨的内容，我们希望像呵护孩子一样呵护我们的作品，使其美观并且生动。 作者认为这是一个很好的方向。\n",
      "\n",
      "\n",
      "生成的最终总结:\n",
      " 这部分内容主要探讨了个体的认知体系和信息处理方式。说明了个体通过对话、看电影、读书或听演讲等活动中的触发点产生兴趣，激发探索欲望，大脑通过强连接记忆和联想信息，使知识体系不断扩大。同时，提出了主动增强弱连结以改善知识体系的建议。内容强调了反馈的重要性，正面反馈可以激发情感，负面反馈则需要理性思考以避免陷入负面评价。最后，作者倡导像呵护孩子一样呵护我们的作品，使其美观生动。\n"
     ]
    }
   ],
   "source": [
    "# summarize each sentence and give a final summary by using GPT-4\n",
    "\n",
    "import re\n",
    "import openai\n",
    "\n",
    "# 设置 API 密钥\n",
    "openai.api_key = \"sk\n",
    "\n",
    "# 从文件读取无标点的输入文本\n",
    "with open(\"D:/output - Copy.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    article_text = file.read()\n",
    "    \n",
    "# 按关键词分割文本成较短的句子\n",
    "split_text = re.sub(r\"(那么|然后|首先|所以|因此|之后|啊|嗯|我觉得|我想|我认为)\", r\". \\1\", article_text)\n",
    "split_sentences = split_text.split(\". \")  # 分割成短句子\n",
    "print(\"分割后的句子:\", split_sentences)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 每 3-4 句话合并为一个段落\n",
    "grouped_sentences = [\" \".join(split_sentences[i:i+3]) for i in range(0, len(split_sentences), 4)]\n",
    "\n",
    "# 对每个段落生成摘要\n",
    "summary_chunks = []\n",
    "for paragraph in grouped_sentences:\n",
    "    if paragraph.strip():  # 忽略空白段落\n",
    "        for attempt in range(3):  # 最多重试 3 次\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-4\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"你是一个帮助生成简短摘要的助手。\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"请对以下内容生成简短的中文摘要：{paragraph}\"}\n",
    "                    ],\n",
    "                    max_tokens=100,  # 设置 max_tokens 以限制摘要长度\n",
    "                    temperature=0.5\n",
    "                )\n",
    "                summary = response['choices'][0]['message']['content']\n",
    "                summary_chunks.append(summary)\n",
    "                break  # 成功后跳出重试循环\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                time.sleep(5)  # 等待几秒后重试\n",
    "                \n",
    "# 合并所有段落的摘要\n",
    "intermediate_summary = \" \".join(summary_chunks)\n",
    "print(\"生成的最终摘要:\\n\", intermediate_summary)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 最后生成一个综合的最终摘要\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个帮助生成简短总结的助手。\"},\n",
    "        {\"role\": \"user\", \"content\": f\"请对以下内容生成简短的综合中文总结：{intermediate_summary}\"}\n",
    "    ],\n",
    "    max_tokens=1000,  # 最终摘要字数限制\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "final_summary = response['choices'][0]['message']['content']\n",
    "print(\"生成的最终总结:\\n\", final_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e5c774-338c-4d42-90b4-d367b520d58f",
   "metadata": {},
   "source": [
    "### NOTE:\n",
    "### 128,000 tokens 是上下文窗口的总大小，包括输入和输出的总和。\n",
    "### 16,384 tokens 是最大输出限制，可以在生成内容时将 max_tokens 设置到 16,384。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ecb6c48-46ab-4b7e-95b4-9b530139f828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割后的句子: ['', '啊好把这一部分的内容总结一下', '首先呢是一个人他有一个认知体系', '那么这个人认知体系他肯定会基于这个人的特色', '然后有一些特定的那个触发点', '那么这个出发点来自于这个人跟其他的事物进行一个交互那这个比如说他可能跟另一个人进行一段对话或者是看了一部电影看了一本书甚至死是听了一部而听了一个演讲', '然后他都会产生一些兴趣点或者是触发点但他觉得眼前一亮想要探索更多', '那么这些出发点之间的有一些可能是抢连结的有一些可能是弱连接的但是现在可能就在一段时间', '之后就就他就回忆不起来了但是强连接的呢他因为大脑比如说基于这个出发点他有很多在接受到这个出发点的时候他有很多联想比如说当然他是主动的进行联想或者是被动了一下', '然后呢这样的话就会让这个出发点呢就会牢牢的就是说被保留在了他的知识体系列在他的知识体系在这个范围内就不断的回扩大', '然后呢因为就是因为这个强连接', '那么这个新的知识听了这个出发点也变成了他只是体系的一个部分', '然后呢也在未来的使用当中更容易被调去但是但是那些弱点可能未来在未来的使用中就被遗忘就不会被调去了', '那么', '然后还有一个方法它能帮助我们去就是主动的去增强这些弱连结', '那么就是人为的进行主动的去教别人或者是去输出比如说路上一个视频写一段话当然在这个过程中呢他就会不断的主动的去掉去', '那么就会加深这个内容跟原有之体系的一些交互', '然后进行连接当然这部分如果要持续的话他就需要一个反馈那个反馈可能就是来自于比如说读者听众任何一个外部的环境', '那么这里就好像有一次的一些现象就是说我们在接收到好的反馈的时候我们的情感恼他会突然就会被激发他就会很快', '然后就是本人的一部分', '那么这个人做这个事情就非常有个动力我们想想一下你还来原来在在学校里面', '嗯跟就收到老师的表扬之类的或者是家长的这个认可', '那么就会特别有动力去把这个事情哦再见这里要干好但是呢如果遇到了负面的反馈的话那就要启动我们的理性脑那我们通过一种合理的解释不要掉入到这个方面富贵的这个循环里面这个负面的评价里面因为如果到了父母评价也', '那么人如果任由这个情绪控制的话那个情绪就会被外界影响就会也变得负面但其实这期的并不重要因为总会有一部分人他会因为我们的一些内容出出', '然后呢得到一些收益但是我们签订要讨论的是我们是不是这一部分内容它是经过我们精心打磨就是清新打造的就像书中描述的一样他说', '我想把我们的作品当成一个孩子一样带出去打扮的漂漂亮亮', '我觉得这个解释平衡的形象生动也让', '我觉得我对于做这个视频博主的这个事情有了一些深入的一些思考和理解', '我觉得这可以是一个很好的一个方向']\n",
      "\n",
      "\n",
      "生成的最终摘要:\n",
      " 一个人拥有自己的认知体系。 人与事物的交互，如对话、电影、书籍或演讲，可能成为触发点，引发兴趣和探索欲望。 大脑在接收到某个出发点时，通过强连接进行主动或被动的联想，使得该出发点在知识体系中得到巩固和扩展。 内容提到未来使用中可能会遗忘弱点，而有方法可以主动增强这些弱连接。 内容提到，通过反馈机制，新的信息可以与原有体系产生交互和连接。外部环境如读者或听众提供的正面反馈会激发情感反应。 正面的反馈如老师和家长的表扬能激发动力，而遇到负面反馈时，应通过理性思考和合理解释避免陷入负面循环。 我们需要讨论的内容是如何精心打磨我们的作品，就像书中所述，把作品当成孩子一样精心装扮。这个比喻形象生动。 这可能是一个很好的方向。\n",
      "\n",
      "\n",
      "生成的最终总结:\n",
      " 一个人拥有自己的认知体系，与外界事物的互动可以激发兴趣和探索欲望。大脑通过联想巩固和扩展知识体系，尽管有遗忘弱点，但可通过方法增强弱连接。通过反馈机制，新的信息与原有体系交互，正面反馈能激发动力，而负面反馈需理性应对。讨论的重点是如何精心打磨作品，将其视为精心装扮的孩子，这一比喻生动且具有指导意义。\n"
     ]
    }
   ],
   "source": [
    "# adjust to use gpt-4o and maximum token.\n",
    "\n",
    "\n",
    "import re\n",
    "import openai\n",
    "\n",
    "# 设置 API 密钥\n",
    "openai.api_key = \"sk\n",
    "\n",
    "# 从文件读取无标点的输入文本\n",
    "with open(\"D:/output - Copy.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    article_text = file.read()\n",
    "    \n",
    "# 按关键词分割文本成较短的句子\n",
    "split_text = re.sub(r\"(那么|然后|首先|所以|因此|之后|啊|嗯|我觉得|我想|我认为)\", r\". \\1\", article_text)\n",
    "split_sentences = split_text.split(\". \")  # 分割成短句子\n",
    "print(\"分割后的句子:\", split_sentences)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 每 3-4 句话合并为一个段落\n",
    "grouped_sentences = [\" \".join(split_sentences[i:i+3]) for i in range(0, len(split_sentences), 5)]\n",
    "\n",
    "# 对每个段落生成摘要\n",
    "summary_chunks = []\n",
    "for paragraph in grouped_sentences:\n",
    "    if paragraph.strip():  # 忽略空白段落\n",
    "        for attempt in range(3):  # 最多重试 3 次\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"你是一个帮助生成简短摘要的助手。\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"请对以下内容生成简短的中文摘要：{paragraph}\"}\n",
    "                    ],\n",
    "                    max_tokens=500,  # 设置 max_tokens 以限制摘要长度\n",
    "                    temperature=0.5\n",
    "                )\n",
    "                summary = response['choices'][0]['message']['content']\n",
    "                summary_chunks.append(summary)\n",
    "                break  # 成功后跳出重试循环\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                time.sleep(5)  # 等待几秒后重试\n",
    "                \n",
    "# 合并所有段落的摘要\n",
    "intermediate_summary = \" \".join(summary_chunks)\n",
    "print(\"每个内容生成的摘要:\\n\", intermediate_summary)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 最后生成一个综合的最终摘要\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个帮助生成简短总结的助手。\"},\n",
    "        {\"role\": \"user\", \"content\": f\"请对以下内容生成简短的综合中文总结：{intermediate_summary}\"}\n",
    "    ],\n",
    "    max_tokens=16384,  # 最终摘要字数限制\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "final_summary = response['choices'][0]['message']['content']\n",
    "print(\"生成的最终总结:\\n\", final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e72ad13-a19b-440b-8564-ff9758ae2585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割后的句子: ['', '啊好把这一部分的内容总结一下', '首先呢是一个人他有一个认知体系', '那么这个人认知体系他肯定会基于这个人的特色', '然后有一些特定的那个触发点', '那么这个出发点来自于这个人跟其他的事物进行一个交互那这个比如说他可能跟另一个人进行一段对话或者是看了一部电影看了一本书甚至死是听了一部而听了一个演讲', '然后他都会产生一些兴趣点或者是触发点但他觉得眼前一亮想要探索更多', '那么这些出发点之间的有一些可能是抢连结的有一些可能是弱连接的但是现在可能就在一段时间', '之后就就他就回忆不起来了但是强连接的呢他因为大脑比如说基于这个出发点他有很多在接受到这个出发点的时候他有很多联想比如说当然他是主动的进行联想或者是被动了一下', '然后呢这样的话就会让这个出发点呢就会牢牢的就是说被保留在了他的知识体系列在他的知识体系在这个范围内就不断的回扩大', '然后呢因为就是因为这个强连接', '那么这个新的知识听了这个出发点也变成了他只是体系的一个部分', '然后呢也在未来的使用当中更容易被调去但是但是那些弱点可能未来在未来的使用中就被遗忘就不会被调去了', '那么', '然后还有一个方法它能帮助我们去就是主动的去增强这些弱连结', '那么就是人为的进行主动的去教别人或者是去输出比如说路上一个视频写一段话当然在这个过程中呢他就会不断的主动的去掉去', '那么就会加深这个内容跟原有之体系的一些交互', '然后进行连接当然这部分如果要持续的话他就需要一个反馈那个反馈可能就是来自于比如说读者听众任何一个外部的环境', '那么这里就好像有一次的一些现象就是说我们在接收到好的反馈的时候我们的情感恼他会突然就会被激发他就会很快', '然后就是本人的一部分', '那么这个人做这个事情就非常有个动力我们想想一下你还来原来在在学校里面', '嗯跟就收到老师的表扬之类的或者是家长的这个认可', '那么就会特别有动力去把这个事情哦再见这里要干好但是呢如果遇到了负面的反馈的话那就要启动我们的理性脑那我们通过一种合理的解释不要掉入到这个方面富贵的这个循环里面这个负面的评价里面因为如果到了父母评价也', '那么人如果任由这个情绪控制的话那个情绪就会被外界影响就会也变得负面但其实这期的并不重要因为总会有一部分人他会因为我们的一些内容出出', '然后呢得到一些收益但是我们签订要讨论的是我们是不是这一部分内容它是经过我们精心打磨就是清新打造的就像书中描述的一样他说', '我想把我们的作品当成一个孩子一样带出去打扮的漂漂亮亮', '我觉得这个解释平衡的形象生动也让', '我觉得我对于做这个视频博主的这个事情有了一些深入的一些思考和理解', '我觉得这可以是一个很好的一个方向']\n",
      "\n",
      "\n",
      "段落 1 的摘要:\n",
      " 一个人拥有自己的认知体系。\n",
      "段落 2 的摘要:\n",
      " 人与事物的交互，如对话、电影、书籍或演讲等，可能激发兴趣或触发点，促使其探索更多。这些出发点之间可能存在强弱连接。\n",
      "段落 3 的摘要:\n",
      " 强连接使新知识更容易融入体系并在未来被调用，而弱连接的知识可能会被遗忘。\n",
      "段落 4 的摘要:\n",
      " 通过主动教别人或输出内容（如制作视频、写文章），可以加深对已有知识体系的理解和连接。为了持续这一过程，需要来自读者或听众等外部环境的反馈。\n",
      "段落 5 的摘要:\n",
      " 人们在受到正面反馈时会更有动力去做好事情，而面对负面反馈时，应通过理性思考和合理解释避免陷入负面循环。\n",
      "段落 6 的摘要:\n",
      " 作者将作品比喻为需要精心打扮的孩子，通过这个形象化的比喻，表达了对视频创作的深入思考和理解。\n",
      "\n",
      "所有摘要合并后的内容:\n",
      " 一个人拥有自己的认知体系。 人与事物的交互，如对话、电影、书籍或演讲等，可能激发兴趣或触发点，促使其探索更多。这些出发点之间可能存在强弱连接。 强连接使新知识更容易融入体系并在未来被调用，而弱连接的知识可能会被遗忘。 通过主动教别人或输出内容（如制作视频、写文章），可以加深对已有知识体系的理解和连接。为了持续这一过程，需要来自读者或听众等外部环境的反馈。 人们在受到正面反馈时会更有动力去做好事情，而面对负面反馈时，应通过理性思考和合理解释避免陷入负面循环。 作者将作品比喻为需要精心打扮的孩子，通过这个形象化的比喻，表达了对视频创作的深入思考和理解。\n",
      "\n",
      "\n",
      "\n",
      "开始对合并后的摘要内容进行重新措辞...\n",
      "\n",
      "重新措辞后的合并摘要:\n",
      " 每个人都有自己独特的认知体系。在与人或事物的互动中，例如通过对话、观看电影、阅读书籍或听演讲，可能会激发兴趣或触发点，促使其进一步探索。这些触发点之间的连接强度各不相同。强连接能够使新知识更容易融入现有体系，并在未来被轻松调用，而弱连接的知识则可能被遗忘。通过主动向他人传授或输出内容（如制作视频、撰写文章），可以加深对已有知识体系的理解和连接。为了使这一过程持续下去，需要来自读者或听众的反馈。正面的反馈能够激励人们更好地完成任务，而面对负面反馈时，人们应通过理性思考和合理解释来避免陷入消极循环。作者将作品比喻为需要精心打扮的孩子，通过这一形象化的比喻，表达了对视频创作的深入思考和理解。\n"
     ]
    }
   ],
   "source": [
    "# give a summary for each sentence and rephrase all summaries after combining them.\n",
    "# the results are good and reasonable.\n",
    "\n",
    "import openai\n",
    "import re\n",
    "import time\n",
    "\n",
    "# 设置 OpenAI API 密钥\n",
    "openai.api_key = \"sk\"\n",
    "\n",
    "# 从文件读取无标点的输入文本\n",
    "with open(\"D:/output - Copy.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    article_text = file.read()\n",
    "    \n",
    "# 按关键词分割文本成较短的句子\n",
    "split_text = re.sub(r\"(那么|然后|首先|所以|因此|之后|啊|嗯|我觉得|我想|我认为)\", r\". \\1\", article_text)\n",
    "split_sentences = split_text.split(\". \")  # 分割成短句子\n",
    "print(\"分割后的句子:\", split_sentences)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# 每 3-4 句话合并为一个段落\n",
    "grouped_sentences = [\" \".join(split_sentences[i:i+3]) for i in range(0, len(split_sentences), 5)]\n",
    "\n",
    "# 对每个段落生成摘要\n",
    "summaries = []\n",
    "for index, paragraph in enumerate(grouped_sentences, 1):\n",
    "    if paragraph.strip():  # 忽略空白段落\n",
    "        for attempt in range(3):  # 最多重试 3 次\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"你是一个帮助生成简短摘要的助手。\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"请对以下内容生成简短的中文摘要：{paragraph}\"}\n",
    "                    ],\n",
    "                    max_tokens=500,  # 设置 max_tokens 以限制摘要长度\n",
    "                    temperature=0.5\n",
    "                )\n",
    "                summary = response['choices'][0]['message']['content']\n",
    "                summaries.append(summary)\n",
    "                print(f\"段落 {index} 的摘要:\\n\", summary)  # 输出摘要\n",
    "                break  # 成功后跳出重试循环\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                time.sleep(5)  # 等待几秒后重试\n",
    "\n",
    "# 所有摘要都生成完毕，合并为一个整体内容\n",
    "combined_summary = \" \".join(summaries)\n",
    "print(\"\\n所有摘要合并后的内容:\\n\", combined_summary)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 对整个摘要内容进行重新措辞\n",
    "print(\"\\n开始对合并后的摘要内容进行重新措辞...\\n\")\n",
    "for attempt in range(3):  # 最多重试 3 次\n",
    "    try:\n",
    "        rephrase_response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"你是一个帮助重新措辞的助手。\"},\n",
    "                {\"role\": \"user\", \"content\": f\"请重新措辞以下内容，使其保持原意,连贯，逻辑通顺：{combined_summary}\"}\n",
    "            ],\n",
    "            max_tokens=16384,  # 设置 max_tokens 控制重新措辞后的长度\n",
    "            temperature=0.5\n",
    "        )\n",
    "        rephrased_combined_summary = rephrase_response['choices'][0]['message']['content']\n",
    "        print(\"重新措辞后的合并摘要:\\n\", rephrased_combined_summary)  # 输出重新措辞后的合并摘要\n",
    "\n",
    "        # 将最终结果保存到 txt 文件\n",
    "        with open(\"D:/optimized_text.txt\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "            output_file.write(rephrased_combined_summary)\n",
    "        \n",
    "        print(\"\\n重新措辞后的合并摘要已保存到 'D:/final_rephrased_summary.txt'\")\n",
    "        break  # 成功后跳出重试循环\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        time.sleep(5)  # 等待几秒后重试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6042d67-4441-42bb-9049-54e06def48e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Users\\User\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ec625d-4dd3-4cfd-be27-6afb5ca6918e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f0f54-a9d3-4253-a51b-60db0eead72e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7cd46c-855c-4fd5-99e2-289cbdcf94d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7bbc4-d1eb-4e1c-9b56-92511422f8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae5614-7e9e-49f2-ad46-abb9ed862220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
